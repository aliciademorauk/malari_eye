{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = np.load(\"../malaria/train_test_data/training_COL_X_all.npy\")\n",
    "y = np.load(\"../malaria/train_test_data/training_COL_y_all.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.imshow(X[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#convert y into OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "ohe.fit(y.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_encoded = ohe.transform(y.reshape(-1,1))# Display the detected categories\n",
    "print(f\"The categories detected by the OneHotEncoder are {ohe.categories_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_encoded_df=pd.DataFrame(y_encoded, columns = ohe.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_encoded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cw = y_encoded_df.sum().to_dict()\n",
    "cw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cwv = class_weight.compute_class_weight('balanced', \n",
    "                            classes = np.unique(y),\n",
    "                            y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z = zip([int(i) for i in (np.arange(0,7))], \n",
    "            cwv)\n",
    "np.unique(y_encoded)\n",
    "[int(i) for i in (np.arange(0,7))]\n",
    "weighting = dict(z)\n",
    "weighting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if X.ndim == 3:\n",
    "    X_expanded = np.expand_dims(X,axis=3)\n",
    "    image_shape = (X_expanded.shape[1], X_expanded.shape[2], X_expanded.shape[3])\n",
    "    X=X_expanded\n",
    "else:\n",
    "    image_shape = (X.shape[1], X.shape[2], X.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X=X/255 #.shape\n",
    "image_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from keras.layers import BatchNormalization\n",
    "\n",
    "# ARCHITECTURE imports\n",
    "\n",
    "# import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import  Sequential, layers, regularizers, metrics\n",
    "\n",
    "# from keras.layers import BatchNormalization\n",
    "\n",
    "#### 1. ARCHITECTURE\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(filters=36, kernel_size=(5,5), input_shape=image_shape, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(layers.Dropout(0.5))\n",
    "# model.add(layers.Conv2D(filters=20, kernel_size=(3,3), activation='relu', kernel_regularizer=tf.keras.regularizers.L1(0.01)))\n",
    "# model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(layers.Conv2D(filters=10, kernel_size=(2,2), activation='relu', kernel_regularizer=tf.keras.regularizers.L1(0.01)))\n",
    "model.add(layers.Conv2D(filters=20, kernel_size=(2,2), activation='relu'))\n",
    "\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#  model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "# Dropouts reduce overfitting by randomly turning neurons off during training.\n",
    "\n",
    "model.add(layers.Dropout(0.2))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "# binary = sigmoid\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "# COMPILATION imports\n",
    "\n",
    "from tensorflow.keras import optimizers, callbacks\n",
    "\n",
    "#### 2. COMPILATION\n",
    "\n",
    "# adam = optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999)\n",
    "# adam = optimizers.Adam(learning_rate=0.1)\n",
    "adam = optimizers.Adam()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy',metrics.Recall()]\n",
    "             )\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FIT imports\n",
    "\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "\n",
    "#### 3. FIT\n",
    "\n",
    "es = callbacks.EarlyStopping(patience=15, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X, y_encoded,\n",
    "          batch_size=64, # Batch size -too small--> no generalization\n",
    "          epochs=100,    #            -too large--> slow computations\n",
    "          validation_split=0.2,\n",
    "          callbacks=[es],\n",
    "          class_weight = weighting,\n",
    "          verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import colors \n",
    "def plot_loss(history, label, n):\n",
    "    axs = plt.gca()\n",
    "    ax2 = axs.twinx()\n",
    "    # Use a log scale on y-axis to show the wide range of values.\n",
    "    axs.semilogy(history.epoch, history.history['loss'],\n",
    "               color='b', label='Train ' + label)\n",
    "    axs.semilogy(history.epoch, history.history['val_loss'],\n",
    "               color='r', label='Val ' + label,\n",
    "               linestyle=\"--\")\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_ylabel('Loss')\n",
    "    ax2.plot(history.epoch, history.history['recall'],\n",
    "           color = 'g', label ='Recall' + label, linestyle = \"-.\")\n",
    "    ax2.plot(history.epoch, history.history['accuracy'],\n",
    "           color = 'y', label ='Recall' + label, linestyle = \"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_loss(history,\"first run\",'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w = model.get_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
